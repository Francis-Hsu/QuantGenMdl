{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bingzhi\\Envs\\tensorCircuit_tf\\lib\\site-packages\\ot\\backend.py:2998: UserWarning: To use TensorflowBackend, you need to activate the tensorflow numpy API. You can activate it by running: \n",
      "from tensorflow.python.ops.numpy_ops import np_config\n",
      "np_config.enable_numpy_behavior()\n",
      "  register_backend(TensorflowBackend())\n",
      "Please first ``pip install -U qiskit`` to enable related functionality in translation module\n",
      "Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import unitary_group\n",
    "from opt_einsum import contract\n",
    "from QDDPM_tf import MultiQubitDiffusionModel, QDDPM\n",
    "from QDDPM_tf import naturalDistance, WassDistance\n",
    "import tensorflow as tf\n",
    "import tensorflow.math as tfm\n",
    "from tensorflow.python.ops.numpy_ops import np_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_config.enable_numpy_behavior()\n",
    "# tc.register_backend(tc.TensorflowBackend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlated noise training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiseTraining_t(model, t, inputs_T, params_tot, Ndata, epochs, dis_measure='nat', dis_params={}):\n",
    "    '''\n",
    "    backward training of QDDPM for correlated noise\n",
    "    Args:\n",
    "    model: the QDDPM\n",
    "    t: diffusion step\n",
    "    params_tot: collection of PQC parameters for steps > t \n",
    "    Ndata: number of samples in training data set\n",
    "    epochs: number of iterations\n",
    "    dis_measure: the distance measure to compare two distributions of quantum states\n",
    "    dis_params: potential hyper-parameters for distance measure\n",
    "    '''\n",
    "    \n",
    "    input_tplus1 = model.prepareInput_t(inputs_T, params_tot, t, Ndata) # prepare input\n",
    "    states_diff = model.states_diff\n",
    "    loss_hist = [] # record of training history\n",
    "    f_hist = [] # record of std of bloch-y cooredinates\n",
    "\n",
    "    tf.random.set_seed(None)\n",
    "    params_t = tf.Variable(tf.random.normal([2 * model.n_tot * model.L]))\n",
    "    # set optimizer and learning rate decay\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        0.01, 200, 0.8, staircase=True)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
    "\n",
    "    for step in range(epochs):\n",
    "        indices = np.random.choice(states_diff.shape[1], size=Ndata, replace=False)\n",
    "        true_data = states_diff[t, indices]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            output_t = model.backwardOutput_t(input_tplus1, params_t)\n",
    "            if dis_measure == 'nat':\n",
    "                # natural distance\n",
    "                loss = naturalDistance(output_t, true_data)\n",
    "            elif dis_measure == 'wd':\n",
    "                # Wassastein distance\n",
    "                loss = WassDistance(output_t, true_data)\n",
    "\n",
    "        grads = tape.gradient(loss, [params_t])\n",
    "        optimizer.apply_gradients(zip(grads, [params_t]))\n",
    "\n",
    "        loss_hist.append(tf.stop_gradient(loss)) # record the current loss\n",
    "        f_hist.append(tf.math.reduce_mean(tf.abs(tf.stop_gradient(output_t)[:,2])**2))\n",
    "\n",
    "    return tf.stop_gradient(params_t), tf.squeeze(tf.stack(loss_hist)), tf.squeeze(tf.stack(f_hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "n, na = 2, 2\n",
    "T = 20\n",
    "L = 6\n",
    "Ndata = 500\n",
    "epochs = 2500\n",
    "repeat = 5\n",
    "method = 'nat'\n",
    "\n",
    "diffModel = MultiQubitDiffusionModel(n, T, Ndata)\n",
    "inputs_T = diffModel.HaarSampleGeneration(Ndata, seed=22)\n",
    "\n",
    "model = QDDPM(n=n, na=na, T=T, L=L)\n",
    "states_diff = np.load('data/corrNoiseDiff_n%dT%d_N5000.npy'%(n, T))\n",
    "model.set_diffusionSet(states_diff)\n",
    "\n",
    "data_path = \"noise/record_%s/\" %method\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "for t in range(T-1, -1, -1):\n",
    "    params_tot = np.zeros((20, 2*(n+na)*L))\n",
    "    for tt in range(t+1, 20):\n",
    "        params_tot[tt] = np.load('noise/record_%s/QDDPMcorrNoiseparams_n%dna%dT%dL%d_t%d_%s.npy'\n",
    "                                % (method, n, na, T, L, tt, method))\n",
    "\n",
    "    params_all = np.zeros((repeat, 2*(n+na)**L))\n",
    "    loss_all = np.zeros((repeat, epochs))\n",
    "    f_all = np.zeros((repeat, epochs))\n",
    "    for trial in range(repeat):\n",
    "        params, loss, f = noiseTraining_t(\n",
    "            model, t, inputs_T, params_tot, Ndata, epochs, method)\n",
    "        params_all[trial] = params.numpy()\n",
    "        loss_all[trial] = loss.numpy()\n",
    "        f_all[trial] = f.numpy()\n",
    "        print(t, trial, loss_all[trial, -1])\n",
    "\n",
    "    idx = np.argmin(loss_all[:, -1])\n",
    "    np.save('noise/record_%s/QDDPMcorrNoiseparams_n%dna%dT%dL%d_t%d_%s.npy'\n",
    "            % (method, n, na, T, L, t, method), params_all[idx])\n",
    "    np.save('noise/record_%s/QDDPMcorrNoiseloss_n%dna%dT%dL%d_t%d_%s.npy'\n",
    "            % (method, n, na, T, L, t, method), loss_all[idx])\n",
    "    np.save('noise/record_%s/QDDPMcorrNoisef_n%dna%dT%dL%d_t%d_%s.npy'\n",
    "            % (method, n, na, T, L, t, method), f_all[idx])\n",
    "\n",
    "    print('corr-noise, na=%d, t=%d, min loss=%s, F10=%s'\n",
    "          % (na, t, loss_all[idx, -1], f_all[idx, -1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identical product of circle training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idProdTraining_t(model, t, inputs_T, params_tot, Ndata, epochs, dis_measure='wd', dis_params={}):\n",
    "    '''\n",
    "    backward training of QDDPM at step t for identical product state\n",
    "    Args:\n",
    "    model: the QDDPM\n",
    "    t: diffusion step\n",
    "    params_tot: collection of PQC parameters for steps > t \n",
    "    Ndata: number of samples in training data set\n",
    "    epochs: number of iterations\n",
    "    dis_measure: the distance measure to compare two distributions of quantum states\n",
    "    dis_params: potential hyper-parameters for distance measure\n",
    "    '''\n",
    "    \n",
    "    input_tplus1 = model.prepareInput_t(inputs_T, params_tot, t, Ndata) # prepare input\n",
    "    states_diff = model.states_diff\n",
    "    loss_hist = [] # record of training history\n",
    "    y1_hist = [] # record of bloch-y coordinates for first qubit\n",
    "    y2_hist = [] # record of bloch-y coordinates for second qubit\n",
    "    # Pauli-y operator on first/second qubit\n",
    "    sy = np.array([[0,-1j], [1j, 0]])\n",
    "    sy1 = tf.cast(tf.convert_to_tensor(np.kron(sy, np.eye(2))), dtype = tf.complex64)\n",
    "    sy2 = tf.cast(tf.convert_to_tensor(np.kron(np.eye(2), sy)), dtype = tf.complex64)\n",
    "\n",
    "    tf.random.set_seed(None)\n",
    "    params_t = tf.Variable(tf.random.normal([2 * model.n_tot * model.L]))\n",
    "    # set optimizer and learning rate decay\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        0.01, 200, 0.8, staircase=True)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "    for step in range(epochs):\n",
    "        indices = np.random.choice(states_diff.shape[1], size=Ndata, replace=False)\n",
    "        true_data = states_diff[t, indices]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            output_t = model.backwardOutput_t(input_tplus1, params_t)\n",
    "            if dis_measure == 'nat':\n",
    "                # natural distance\n",
    "                loss = naturalDistance(output_t, true_data)\n",
    "            elif dis_measure == 'wd':\n",
    "                # Wassastein distance\n",
    "                loss = WassDistance(output_t, true_data)\n",
    "\n",
    "        grads = tape.gradient(loss, [params_t])\n",
    "        optimizer.apply_gradients(zip(grads, [params_t]))\n",
    "\n",
    "        loss_hist.append(tf.stop_gradient(loss)) # record the current loss\n",
    "        y1 = tfm.real(contract('mi, ij, mj-> m',  tfm.conj(tf.stop_gradient(output_t)), sy1, tf.stop_gradient(output_t)))\n",
    "        y2 = tfm.real(contract('mi, ij, mj-> m',  tfm.conj(tf.stop_gradient(output_t)), sy2, tf.stop_gradient(output_t)))\n",
    "        y1_hist.append(y1)\n",
    "        y2_hist.append(y2)\n",
    "\n",
    "    y1_hist = tf.stack(y1_hist)\n",
    "    y2_hist = tf.stack(y2_hist)\n",
    "    return tf.stop_gradient(params_t), tf.squeeze(tf.stack(loss_hist)), y1_hist, y2_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prodHaarStates(n, Ndata, seed):\n",
    "    '''\n",
    "    generate two-qubit product states of one-qubit Haar random states\n",
    "    '''\n",
    "    np.random.seed(seed)\n",
    "    state_qs = unitary_group.rvs(2, size=n*Ndata)[:, :, 0]\n",
    "    state_qs = np.split(state_qs, n, axis=0)\n",
    "    states = state_qs[0]\n",
    "    for i in range(1, n):\n",
    "        states = contract('mi, mj->mij', states, state_qs[i]).reshape((Ndata, 2**(i + 1)))\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, na = 2, 4\n",
    "T = 20\n",
    "L = 10\n",
    "Ndata = 500\n",
    "epochs = 2500\n",
    "repeat = 5\n",
    "method = 'wd'\n",
    "\n",
    "inputs_T = prodHaarStates(n, Ndata, seed=22)\n",
    "\n",
    "model = QDDPM(n=n, na=na, T=T, L=L)\n",
    "states_diff = np.load('data/idProdDiff_n%dT%d_N5000.npy'%(n, T))\n",
    "model.set_diffusionSet(states_diff)\n",
    "\n",
    "data_path = \"product/record_%s/\" %method\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "for t in range(T-1, -1, -1):\n",
    "    params_tot = np.zeros((20, 2*(n+na)*L))\n",
    "    for tt in range(t+1, 20):\n",
    "        params_tot[tt] = np.load('product/record_%s/QDDPMidProdparams_n%dna%dT%dL%d_t%d_%s.npy'\n",
    "                                %(method, n, na, T, L, tt, method))\n",
    "\n",
    "    params_all = np.zeros((repeat, 2*(n + na)*L))\n",
    "    loss_all = np.zeros((repeat, epochs))\n",
    "    y1_all = np.zeros((repeat, epochs, Ndata))\n",
    "    y2_all = np.zeros((repeat, epochs, Ndata))\n",
    "\n",
    "    for trial in range(repeat):\n",
    "        params, loss, y1, y2 = idProdTraining_t(model, t, inputs_T, params_tot, Ndata, epochs, method)\n",
    "        params_all[trial] = params.numpy()\n",
    "        loss_all[trial] = loss.numpy()\n",
    "        y1_all[trial] = y1.numpy()\n",
    "        y2_all[trial] = y2.numpy()\n",
    "        print(t, trial, loss_all[trial, -1])\n",
    "        \n",
    "    idx = np.argmin(loss_all[:, -1])\n",
    "    np.save('product/record_%s/QDDPMidProdparams_n%dna%dT%dL%d_t%d_%s.npy'\n",
    "            % (method, n, na, T, L, t, method), params_all[idx])\n",
    "    np.save('product/record_%s/QDDPMidProdloss_n%dna%dT%dL%d_t%d_%s.npy'\n",
    "            % (method, n, na, T, L, t, method), loss_all[idx])\n",
    "    np.save('product/record_%s/QDDPMidPrody1_n%dna%dT%dL%d_t%d_%s.npy'\n",
    "            % (method, n, na, T, L, t, method), y1_all[idx])\n",
    "    np.save('product/record_%s/QDDPMidPrody2_n%dna%dT%dL%d_t%d_%s.npy'\n",
    "            % (method, n, na, T, L, t, method), y2_all[idx])\n",
    "\n",
    "    print('id-product, na=%d, t=%d, min loss=%s, (y1-y2)^2=%s'\n",
    "          % (na, t, loss_all[idx, -1], np.mean((y1_all[idx, -1]-y2_all[idx, -1])**2)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area-law entanglement training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorcircuit_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
